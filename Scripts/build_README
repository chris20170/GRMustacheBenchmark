#!/usr/bin/env ruby
require 'fileutils'
require File.join(File.dirname(__FILE__), 'GRMustacheBenchmark')

ROOT = File.join(File.dirname(__FILE__), '..')
plots_path = File.join(ROOT, 'Plots')
LABEL_FOR_TASK = {
  'parse' => 'Parsing',
  'render' => 'Rendering',
}

benchmark = GRMustacheBenchmark.new(ROOT)

benchmark.complexities.each do |complexity|
  benchmark.tasks.each do |task|
    unless File.exist?(plots_path)
      Dir.mkdir(plots_path)
    end
    gnuplot_data_path = File.join(plots_path, "#{complexity}-#{task}.dat")
    File.open(gnuplot_data_path, 'w') do |f|
      benchmark.versions.each_with_index do |version, index|
        sample = begin benchmark.sample_for_version_complexity_task(version, complexity, task) / benchmark.min_sample rescue '' end
        f.puts "#{version.gsub(/^[^\d]*([\d])/,'\1')}\t#{sample}"
      end
    end
    plot_path = File.join(plots_path, "#{complexity}-#{task}.png")
    title = "#{task} (complexity #{complexity})"
    gnuplot_conf_path = File.join(plots_path, "#{complexity}-#{task}.conf")
    File.open(gnuplot_conf_path, 'w') do |f|
      f.write <<-GNUPLOT
        set terminal png size 390,200 small

        # Extract min and max values
        set output "/dev/null"
        ismin(x) = (x<Y_MIN)?Y_MIN=x:0
        ismax(x) = (x>Y_MAX)?Y_MAX=x:0
        Y_MAX=-1e38
        Y_MIN=1e38
        plot "#{gnuplot_data_path}" u :(ismin($2)*ismax($2))

        set output "#{plot_path}"
        set title "#{title}"
        set tmarg 2
        set rmarg 0
        set bmargin 4
        set lmarg 6
        set xtics rotate
        set yrange [0:Y_MAX*1.05]
        set style data histogram
        set style fill solid
        plot "#{gnuplot_data_path}" using 2:xticlabels(1) title "", \
             Y_MIN with lines title ""
      GNUPLOT
    end
    `/usr/local/bin/gnuplot < #{gnuplot_conf_path}`
    FileUtils.rm(gnuplot_data_path)
    FileUtils.rm(gnuplot_conf_path)
  end
end

puts <<-MARKDOWN
# GRMustache benchmarks

You can here compare the performance of all [GRMustache](https://github.com/groue/GRMustache) versions since v1.10.2.

GRMustache has been tested against random templates of various complexities, containing an average of 2, 10, or 100 elements (text, `{{variable}}` tags, or `{{#section}}` tags).

For each version and complexity, we benchmark two different tasks: parsing, and rendering.

Those benchmarks are relative, not absolute: numbers have no unit. They are all relative to the time taken by the shortest task, which is given the score 1.

<table border="0" cellspacing="0" cellpadding="0">
MARKDOWN

benchmark.complexities.each do |complexity|
  puts "<tr>"
    benchmark.tasks.each do |task|
      puts "<td>"
      puts "<img src=\"/groue/GRMustacheBenchmark/master/Plots/#{complexity}-#{task}.png\" alt=\"Plot for task '#{task}' and complexity '#{complexity}'\">"
      puts "</td>"
    end
  puts "</tr>"
end

puts <<-MARKDOWN
</table>

MARKDOWN


time_precision = 1
time_width = time_precision+6
sample_column_width = [benchmark.complexities.map(&:length).max, time_width].max + 2
version_column_width = benchmark.versions.map(&:length).max + 2
sample_format = "%%%d.%de" % [time_width, time_precision]
line_format = ("\t%%-%ds" % version_column_width) + (("%%%ds" % sample_column_width) * benchmark.complexities.count)
benchmark.tasks.each do |task|
  puts
  puts "## #{LABEL_FOR_TASK[task]} task"
  puts
  puts line_format % ([""]+benchmark.complexities)
  benchmark.versions.reverse.each do |version|
    time_strings = benchmark.complexities.map do |complexity|
      sample = begin benchmark.sample_for_version_complexity_task(version, complexity, task) / benchmark.min_sample rescue nil end
      if sample
        sample_format % sample
      else
        "n/a"
      end
    end
    puts line_format % ([version] + time_strings)
  end
end

puts <<-MARKDOWN

-----

This README.md file has been generated with the `make` command.

MARKDOWN
